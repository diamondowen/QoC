
\documentclass[journal]{IEEEtran}
\IEEEoverridecommandlockouts


% correct bad hyphenation here
\hyphenation{op-tical net-works semi-conduc-tor}
\usepackage{epsfig,cite,amsmath}
\usepackage{graphicx,array,subcaption}
\usepackage{amssymb}
\usepackage{epstopdf}
\usepackage{indentfirst}
\usepackage{lettrine}
\usepackage[lowtilde]{url}


\everymath{\displaystyle}
\newcommand{\tab}[1]{\hspace{.02\textwidth}\rlap{#1}}
\begin{document}
%
% paper title
% can use linebreaks \\ within to get better formatting as desired
\title{Quality-of-Content (QoC)-Based Wireless Video Transmissions: A Joint Source Coding and APP-FEC Rate Allocation Scheme for Human Detections in Mobile Surveillance Networks}


% author names and affiliations
% use a multiple column layout for up to three different
% affiliations
\author{\IEEEauthorblockN{Xiang Chen, Jenq-Neng Hwang, Kuan-Hui Lee, Ricardo L. de Queiroz}   \\
\thanks{This study is partially supported by the “103-EC-17-A-03-S1-214” project from the Ministry of Economic Affairs (MOEA) of Taiwan and “Advanced Wireless Broadband System and Inter-networking Application Technology Development Project” of the Institute for Information Industry which is subsidized by the Ministry of Economy Affairs of Taiwan.}
\thanks{Xiang Chen is with the Department
of Electrical Engineering, University of Washington, Seattle,
WA, 98195 USA (e-mail: xchen28@uw.edu).}% <-this % stops a space
\thanks{Jenq-Neng Hwang is with the Department
of Electrical Engineering, University of Washington, Seattle,
WA, 98195 USA (e-mail: hwang@uw.edu).}% <-this % stops a space
\thanks{Kuan-Hui Lee is with the Department
of Electrical Engineering, University of Washington, Seattle,
WA, 98195 USA (e-mail: ykhlee@uw.edu).}
\thanks{Ricardo L. de Queiroz is with the Department
of Computer Science, Universidade de Brasilia, Brasilia, Brazil (e-mail: queiroz@ieee.org).}

}

% make the title area
\maketitle


\begin{abstract}
%\boldmath
More than 70 percent of all the consumer mobile Internet traffic will be mobile video transmissions in 2019. The development of wireless video transmission technologies have been boosted by the rapidly increasing demand of video streaming applications. Although more and more videos are delivered for video analytics purposes (e.g., object detection/tracking and action recognition, etc.), however, most of existing wireless video transmission schemes are developed to optimize human perception qualities, which are no longer optimal for video analyses.  In mobile surveillance networks, a cloud server collects videos from multiple moving cameras and detects suspicious people in all the camera views. Due to the mobility of the moving cameras such as smartphone or dash cameras, videos have to be uploaded through bandwidth-limited and error-prone wireless networks, which may cause quality degradation of the decoded videos and jeopardize the performance of video analyses. In this paper, we propose an effective rate allocation scheme for multiple moving cameras so that the human detection (content) performance can be improved. Therefore, the optimization criterion of the proposed rate allocation scheme is driven by quality-of-content (QoC). Both video source coding and application layer forward error correction (APP-FEC) coding rates are jointly optimized. Moreover, the proposed rate allocation problem is formulated as a convex optimization problem and can be efficiently solved by standard solvers. Plenty of simulations with the high efficient video coding (HEVC) encoded video sequences and the deformable part model (DPM) object detector demonstrate the effectiveness and favorable performance of our proposed scheme under different pedestrain densities and wireless conditions. 

\begin{IEEEkeywords}
Quality-of-content (QoC), rate allocation, application-layer forward error correction (APP-FEC), video analysis, human detection, visual surveillance, convex optimization
\end{IEEEkeywords}


\end{abstract}

\section{Introduction}
It is predicted that $72$ percent of all the consumer mobile Internet traffic will be mobile video transmissions in $2019$, up from $55$ percent in $2014$ \cite{Cisco}. Moreover, the compound annual growth rate (CAGR) of mobile data traffic is predicted as $57$ percent, which is about three times faster than fixed IP traffic. However, the bandwidth-limited and error-prone nature of wireless communication environements creates challenges for the bandwidth-consuming and delay-sensitive wireless video streaming applications \cite{CHRL15}. High packet loss/error rate, large delay and jitter experienced in wireless networks can cause tremendous quality degradation of received videos, which is required to be studied and solved. 

The exponentially increasing demand of video streaming services has boosted the developement of wireless video transmission technologies \cite{Hwan09}. In most of the existing studies, the optimization targets for wireless video delivery are either quality-of-service (QoS) \cite{Hwan09,EhHa12,KPKG15} or quality-of-experience (QoE) \cite{CHLC15,CHWL14,CDHR15,SHJE13,YaFA15}. For QoS-based design, the transmission scheme is optimized for network parameters such as packet loss rate, delay, jitter, etc. For QoE-based design, QoS measurements are mapped to users' perception and experience of decoded videos so that video transmission parameters can be adjusted to improve users' satisfaction \cite{FiHT10}. Both subjective and objective video quality measurements can be applied to quantify the QoE-based system design \cite{MSSB10}.

The Internet of Things (IoT) becomes a novel paradigm in modern wireless telecommunications \cite{AtIM10}. And video-based IoT, which integrates image processing, computer vision and network frameworks, will help develop a new challenging scientific research area at the intersection of video and network technologies \cite{GBMP13}. Such research areas include surveillance system, automatic behavior analysis and event detection, etc. \cite{GBMP13}. In fact, more and more videos are transmitted for video analytics purposes rather than human perceptions. In \cite{LeHC15}, a vehicle tracking system with static surveillance cameras is developed. In \cite{ChHw14}, an unsupervised learning of camera link models for tracking humans across nonoverlapping static cameras is invented. Based on human detectors, pedestrian tracking systems in single moving cameras are proposed \cite{LHOP14,HWLH15}. A system of on-road pedestrian tracking across multiple moving cameras is studied in \cite{LeHw15}. Due to the large computational cost of video analyses applications and the inter-cooperating properties between multiple cameras, videos are required to be uploaded to a cloud server through wired and/or wireless networks. However, transmitting videos based on QoS or QoE based on existing designs are no longer optimal if the videos are delivered for video analyses. Therefore, it is necessary to develope more efficient video transmission schemes specifically for video analysis and computer vision applications. 

Mobile surveillance networks with multiple moving cameras, which have more flexible camera views comparing to traditional surveillance systems with static closed circuit television (CCTV), is introduced for better crime investigation and tragedy prevention \cite{LeHw15}. In mobile surveillance systems, videos are recorded by driving recorders (dash cameras) or smartphone cameras, and uploaded to remote cloud servers for further automatic video analyses. Due to the mobility nature of moving cameras, wireless wide area networks (WWAN) have to be used for video transmissions. Therefore, efficient video compression, error protection and resource allocation are needed because of the bandwidth-limited and the error-prone nature of wireless networks. 

In mobile surveillance networks, in order to recognize and track suspicious people, several video analysis technologies need to be applied such as human detection, human tracking, action recognition, behavior understanding, etc.. Among these technologies, human detection is the first step and the performances of other human-related video analysis applications are critically affected by the human detection results \cite{LeHw15}. Although plenty of work has been conducted to improve the object detector in computer vision field \cite{DaTr05,LeLS08,FGMR10}, few studies can be found in wireless video transmission area when the performance degradations caused by video compression, wireless transmission errors are considered. In \cite{MiBR13}, a saliency-based rate control system for human detection with a single camera is proposed. To improve the human detection accuracy, this scheme adaptively adjusts the quantization parameters (QPs) to preserve regions with small contrast from excessive smoothing based on a properly designed saliency map. In \cite{CHLQ15}, we proposed a video srouce encoding rate allocation scheme when multiple moving cameras compete for a limited amount of wireless resource. This scheme adequately allocate the wireless resource to each moving camera based on its previous human detection results (contents). Since the optimization objective is to improve human detection performance, this scheme is called a quality-of-content (QoC)-based design.

In this paper, we extend our previous work in \cite{CHLQ15} by considering packet losses in wireless networks. Among several techniques of improving the reliability of data transmissions, we adopte the application layer forward error correction (APP-FEC) code since it can provide certain correction capability without retransmissions, which is suitable for delay-sensitive real-time video streaming applications \cite{JuFJ09,LuSW08,CHRL15}. With APP-FEC, well-designed redundant packets are transmitted along with data packets. By receiving enough subset of data and redundant packets, all of the original data packets can be recovered \cite{JuFJ09}. The correction capability becomes higher with more redundant packets in a coding block. In mobile surveillance networks, each mobile node (moving camera) is allocated certain amounts of wireless resource for video encoding and APP-FEC encoding. Nevertheless, the number of transmitted packets is limited by the total available system bandwidth. With higher/lower source encoding rate, the video analysis performance becomes better/worse with the cost of lower/higher APP-FEC protection capability. Therefore, a QoC-driven joint source coding and APP-FEC rate allocation scheme is proposed in this paper. Instead of considering human perception in traditional video streaming design, the proposed scheme optimizes the human detection performance at the cloud server when multiple mobile nodes compete for the limited wireless resource and upload vidoes via WWAN with a total data rate constraint. The proposed scheme can be formulated as a convex optimization problem \cite{BoVa04} and can be solved by convex optimization toolbox such as CVX \cite{CVX}. To the best of our knowledge, there is no QoC-driven work conducted when both video compressions and wireless transmission errors are considered.

The rest of this paper is organized as follows. In Section II, scenario and system structure of the mobile surveillance network is described. In Section III, the effects of source coding rate on the humant detection performance are studied. Detailed description about the APP-FEC is given in Section IV. The proposed joint source coding and APP-FEC rate allocation scheme is given in Section V. Simulation results are shown in Section VI, followed by the conclusion remarks in Section VII.

\textit{Notations:} The list of symbols used in this paper is summarized in Table \ref{Table: notations}.
\begin{table}[t]
\renewcommand{\arraystretch}{1.3}
\caption{List of symbols}
%\vspace{-.2in}
\begin{center}
\begin{tabular}{|p{0.45 in}|p{2.5 in}|}
\hline
\textbf{Symbol} & \textbf{Definition}  \\
\hline
$q$ & \text{Quantization parameter (QP)} \\ \hline
$P\left(\cdot\right)$ & Human detection accuracy model \\ \hline
$n$ & Application layer forward error correction (APP-FEC) block size \\ \hline
$k$ & Number of source packets in an APP-FEC block \\ \hline
$t$ & Correction capability of an APP-FEC block \\ \hline
$\epsilon$ & Reception overhead efficiency of APP-FEC \\ \hline
$p$ & Probability of packet loss \\ \hline
$f\left(\cdot\right)$ & APP-FEC block correction rate \\ \hline
$\Phi\left(\cdot\right)$ & Cumulative distribution function of the standard Gaussian distribution \\ \hline
$M$ & Total number of mobile nodes in the system \\ \hline
$T^{\left(\text{GoP}\right)}$ & Group of pictures (GoP) time period \\
$S$ & Packet size \\ \hline
$N_m$ & Number of detected people in the view of the mobile node $m$ \\ \hline
$R^{\left(\text{T}\right)}$ & Total data rate target of the system \\ \hline
$R^{\left(\min\right)}$ & Minimum data rate requirement of each mobile node \\ \hline
$\mathbb{N}$ & Set of nature numbers \\ \hline
$c_m^{\left(1\right)}, c_m^{\left(2\right)}$ & Parameters in QP-rate model of the mobile node $m$ \\ \hline
$r_m^{\left(\text{S}\right)}$ & Source coding rate target of the mobile node $m$ \\ \hline
$r_m^{\left(\text{B}\right)}$ & Transmission data rate target of the mobile node $m$ \\ \hline
$c_m^{\left(3\right)}$, $c_m^{\left(4\right)}$ & Parameters in a rate-distortion model of the MSE-driven rate allocation scheme in the control group. \\ \hline
$d_m\left(\cdot\right)$ & Distortion measured by the MSE in a rate-distortion model of the MSE-driven rate allocation scheme in the control group. \\ \hline
$P^{\left(\text{req}\right)}$ & FEC block correction rate requirement of the MSE-driven rate allocation scheme in the control group. \\

\hline
\end{tabular}
\end{center}
\label{Table: notations}
%\vspace{-.1in}
\end{table}

\begin{figure}[t]
\vspace{-.06in}
\centering{\includegraphics[width=3.5 in]{Fig/scenario.pdf}}
\caption{Scenario of mobile surveillance network.}
\label{fig:scenario}
\end{figure}

\begin{figure}[t]
%\vspace{-.2in}
\centering{\includegraphics[width=3.5 in]{Fig/system.pdf}}
\caption{Proposed system structure.}
\label{fig:system}
\end{figure}

\begin{figure}[t]
%\vspace{-.2in}
\centering{\includegraphics[width=3.5 in]{Fig/GOP_FEC.pdf}}
\caption{GoP-level APP-FEC encoding \cite{WSHZ13}.}
\label{fig:GOP_FEC}
\end{figure}
\section{Scenarios and System Structure}
In a mobile surveillance network, multiple mobile nodes are randomly distributed and moving around in the area with different pedestrain densities as illustrated in Fig. \ref{fig:scenario}. Each mobile node can capture, encode and upload videos via a WWAN to a cloud server for video analyses such as human detection. The proposed system structure is shown in Fig. \ref{fig:system}. The captured camera view of each node is encoded with the high efficiency video coding (HEVC) \cite{SOHW12} encoder with different encoding data rates. The parameter estimation module determines the necessary parameters required by the cloud server. The encoded video packets and corresponding parameter packets of a single group of pictures (GoP) is then fed into the APP-FEC encoder, which generates certain amount of redundant packets and forms an APP-FEC block \cite{WSHZ13,BaTO08}. The concept of GoP-level APP-FEC encoding is shown in Fig. \ref{fig:GOP_FEC}. The cloud server receives the transmitted APP-FEC block with some packet lost due to either wireless transmission errors or network congestions. In this paper, the packet loss rate of each mobile node is assumed to be perfectly known by standard real-time protocol (RTP) and real-time control protocol (RTCP) \cite{Perk03,CHWY15}. The APP-FEC decoder decodes the APP-FEC block and fed the video packets to the video decoder. If the number of packet loss is higher than the correction capability of the APP-FEC block, the whole block is then dropped. The video decoder can conceal the lost video frames by copying the last successfully decoded video frame. After decoding the video, an object detection module performs the human detections and sends the detection results (content information) to the rate allocation module. Since the pedestrain densitie is different in the view of each mobile node, the human detection result (content information) is therefore different. Based on the content information and the necessary parameters delivered by the mobile nodes, the rate allocation module jointly optimizes the source coding rate and the APP-FEC coding rate for each mobile node under a pre-determined total data rate constraint, which is assumed to be affordable by the wireless network. The rate allocation result is then fed back to the mobile nodes for encoding and transmission process in the next iteration. Note that the rate allocation results are targets for the mobile nodes and the actural source coding and APP-FEC rates can be slightly different to the targets.


\section{Human Detectors and the Effect of Video Quality on Human Detection Performance}
Plenty of object detection schemes have been developed in existing literatures. A human detector based on the histogram of oriented gradient (HOG) features is proposed in \cite{DaTr05}, which can effectively represent the shape of human. In \cite{LeLS08}, the implicit shape model (ISM) is proposed, which applies a voting scheme based on multi-scale interest points to create plenty of detection hypotheses, and a codebook is used to preserve the trained features. In \cite{FGMR10}, authors extend the idea in \cite{DaTr05} and proposed the deformable part model (DPM), which uses a root model and several part models to describe different partitions of an object. The part models are spatially connected with the root model based on a predefined geometry so that the object can be accurately depicted. Among these object detection methods, the DPM is a well-accepted robust and computational efficient scheme. Therefore, the DPM is adopted as the human detection scheme in this paper. 

Since the DPM object detector is based on HOG features, it can be affected by the artifacts created from video encoders with different compression ratios \cite{MiBR13}. In mobile surveillence systems, human detection is performed in the cloud server based on compressed videos, which may affect the human detection performance. A comparison example of the DPM detection results are shown in Fig \ref{fig:DPMComp}. The video clips ``LOEWENPLATZ" and ``BAHNHOF" in the ETHZ dataset \cite{ELSG08} are encoded by two different QPs. When the QP is large, the artifact caused by higher compression ratio significantly distorts the original HOG information, which leads to noticeable human detection performance degradations.


\begin{figure}[t]
%\vspace{-.2in}
\centering
\begin{subfigure}{1\columnwidth}
\centering{\includegraphics[width=3.5 in]{Fig/DPMComp.pdf}}
\caption{Video clip: “LOEWENPLATZ” in the ETHZ dataset \cite{ELSG08}. Left: QP=$15$; Right: QP=$39$}
\end{subfigure}
~
\begin{subfigure}{1\columnwidth}
\centering{\includegraphics[width=3.5 in]{Fig/DPMComp_2.pdf}}
\caption{Video clip: “BAHNHOF” in the ETHZ dataset \cite{ELSG08}. Left: QP=$15$; Right: QP=$39$}
\end{subfigure}
\caption{Comparisons of Human Detection Performance of the DPM with Different Video Encoding Qualities.}
\label{fig:DPMComp}
%\vspace{-.2in}
\end{figure}


Figure \ref{fig:accuracy} shows the human detection accuracy with respect to different video encoding qualities in terms of the QPs. Six video clips in the ETHZ dataset \cite{ELSG08} are encoded by the HEVC encoder \cite{X265} with $11$ different QPs from $15$ to $45$. The detection results of each video frame is compared with the ground-truth labels provided in the ETHZ dataset. An object is considered as correct detection if the overlapped area of the detection result and the corresponding ground-truth is larger than $50$ percent of the ground-truth area \cite{FGMR10}. Obviously, the detection accuracy is increasing as the video quality is increasing (i.e., the QP is decreasing). But the rate of increasing becomes small when the video quality is high enough since the artifact created by video compression is negligible. By adopting curve-fitting, the human detection accuracy model as a function of QP (i.e., $q$) can be approximated as:
\begin{equation}\label{eq:accuracy_model}
P\left(q\right) = -0.0098\cdot 2^{0.1206\cdot q}+0.6049.
\end{equation}
The solid line in Fig. \ref{fig:accuracy} is based on Eq. \eqref{eq:accuracy_model}. The root mean square error (RMSE) of the curve-fitting in Fig. \ref{fig:accuracy} is $1.104\%$.


\begin{figure}[t]
\centering{\epsfig{file=Fig/accuracy.eps,width=3.5in}}
\caption{Human detection accuracy with different QPs. The solid line is based on a human detection accuracy model given in Eq. \eqref{eq:accuracy_model}. The RMSE of this curve-fitting is $1.104\%$}\label{fig:accuracy}
\end{figure}

\section{APP-FEC and Block Correction Rate}
APP-FEC can provide reliable end-to-end streaming applications with packet level protection \cite{LuSW08}. Suppose a source block with $k$ packets is encoded into an APP-FEC block consisting $n \left(n\geq k\right)$ packets by adding $n-k$ redundant packets, an ideal APP-FEC decoder can reconstruct the original $k$ source packets from any $k$ out of $n$ received packets \cite{LuSW08} with correction capability $t=n-k$. The Reed-Solomon (RS) code, which operates on non-binary symbols, is a well-known APP-FEC scheme with ideal correction capability. However, the block size of RS code is constrained by the symbol size, which limits the flexibility of parameter selections in practice. For instance, considering the most commonly used RS code with $8$ bits per symbol, the total number of packets in an APP-FEC block is constrained by $255$, i.e., $k\leq n \leq 255$. Furthermore, the non-binary operations of the RS code cause high computational complexity in software \cite{LuSW08}. Such drawbacks make the RS code unattractive to high definition (HD) video streaming applications. With the development of APP-FEC, more practical schemes have been introduced. One of the attractive APP-FEC solutions for HD video streaming services is the Raptor code \cite{Shok06}, which has flexible parameters selection and linear decoding cost. Unlike the RS code, the correction capability of a Raptor code is unideal, given by $t=n\left(1+\epsilon\right)k$, where $\epsilon$ is reception overhead efficiency. Nevertheless, the reception overhead efficiency of standardized Raptor code is very low and close to ideal correction capability \cite{LuSW08}. In this paper, the APP-FEC scheme with ideal correction capabiity is assumed for simplicity.

An APP-FEC block can be successfully decoded if the number of packet loss/error is not more than the correction capability $t$. If the packet losses are independent and identical distributed (\textit{i.i.d.}), the block correction rate (BCR) of an $\left(n,k\right)$ ideal APP-FEC code is given by a cumulative distribution function (CDF) of a Binomial distribution \cite{HHWL12}:
\begin{equation} \label{eq:BCR}
f=\sum_{j=0}^{t}\binom{n}{j}p^j\left(1-p\right)^{n-j},
\end{equation}
where $p$ is the packet loss rate. When $n$ is sufficiently large, $np\gg1$ and $n\left(1-p\right)\gg1$, the CDF of a Binomial distribution can be approximated by a CDF of Gaussian distribution with mean $np$ and variance $np\left(1-p\right)$ \cite{StWo11}. Therefore, Eq. \eqref{eq:BCR} can be approximated as:
\begin{equation} \label{eq:BCR_appx1}
f\approx \Phi\left(\frac{t-np}{\sqrt{np\left(1-p\right)}}\right)-\Phi\left(\frac{-np}{\sqrt{np\left(1-p\right)}}\right),
\end{equation}
where $\Phi\left(\cdot\right)$ is the CDF of the Gaussian distribution with $0$ mean and unit variance. If $np$ is large enough, The second term in Eq. \eqref{eq:BCR_appx1} is approximately $0$. And the BCR in Eq. \eqref{eq:BCR} can be further approximated as:
\begin{equation}\label{eq: BCR_appx_final}
f\approx \Phi\left(\frac{n-k-np}{\sqrt{np\left(1-p\right)}}\right)=\Phi\left(\frac{\sqrt{n}\left(1-p\right)-\frac{k}{\sqrt{n}}}{\sqrt{p\left(1-p\right)}}\right).
\end{equation}
When the APP-FEC block is formed every GoP time period (e.g., $0.5 - 1$ second), the APP-FEC block size $n$ is normally large enough with the available data rate to transmit HD videos in modern wireless network (e.g., 10 Mbps) and a reasonable packet size (e.g., $600$ bytes). With a typical packet loss rate in wireless networks without any other protection or retransmission schemes (e.g., $0.1 \% - 2 \%$), the approximation in Eq. \eqref{eq: BCR_appx_final} is valid.

\section{Proposed Joint Source Coding and APP-FEC Rate Allocation Scheme}
Since the wireless resoure is limited, multiple moving nodes have to compete for the total available data rate. Moreover, for each moving node, part of the allocated wireless resource need to be used for APP-FEC redundant packet in order to protect the source packets from possible packet losses. Therefore, it is necessary to design an efficient rate allocation scheme for both video and APP-FEC encodings. Unlike previous studies, which optimize the video decoding quality, the objective of our proposed scheme is to maximize the human detection performance at the cloud server. More specifically, the proposed scheme maximizes the overall true-positive human detection probability under a total data rate constraint and minimum data rate requirements for each moving node, i.e.,
\begin{equation}\label{eq:original_probelm}
\begin{array}{rl}
\max_{\mathbf{k,n}}&\prod_{m=1}^{M}\!\!\left(\!\!P\left(q_m\left(\frac{k_m\cdot S}{T^{\left(\text{GoP}\right)}}\right)\right)\!\!f_m\left(k_m,n_m\right)\!\!\right)^{N_m}\\
\text{subject to}&\sum_{m=1}^{M}n_m\leq\frac{R^{\left(\text{T}\right)}T^{\left(\text{GoP}\right)}}{S},\\
& k_m \geq \frac{R^{\left(\min\right)}T^{\left(\text{GoP}\right)}}{S}, \forall m,\\
& n_m \geq k_m, \forall m,\\
& \mathbf{k},\mathbf{n}\in\mathbb{N}^{M\times 1},
\end{array}
\end{equation}
where $\mathbf{k}$ is an $M\times 1$ vector with each element $k_m$ representing the number of source packets of the mobile node $m$ in an APP-FEC block, $\mathbf{n}$ is an $M\times 1$ vector with each element $n_m$ representing the APP-FEC block size of the mobile node $m$, $M$ is the total number of mobile nodes in the system, $N_m$ is the total number of detected object of the mobile node $m$ in the last GoP time period, $R^{\left(\text{T}\right)}$ is the total available data rate, $T^{\left(\text{GoP}\right)}$ is the GoP time period, $S$ is the packet size. $R^{\left(\min\right)}$ is the minimum data rate requirement so that the minimum detection capability can be maintained for each mobile node. $P\left(\cdot\right)$ is the human detection accuracy in Eq. \eqref{eq:accuracy_model}. $f_m\left(\cdot\right)$ is the APP-FEC BCR in Eq. \eqref{eq:BCR}. $q_m\left(k_m\right)$ is the QP, which is a function of $k_m$ and therefore, a function of source encoding rate $r_m^{\left(\text{S}\right)}=k_m\cdot S/T^{\left(\text{GoP}\right)}$. In this paper, we adopt the following model to fit the QP with respect to the source coding rate, i.e.,
\begin{equation}\label{eq:qp_rate_model}
q_m\left(r^{\left(\text{S}\right)}\right) = \frac{1}{c_m^{\left(2\right)} }\log\left(\frac{r^{\left(\text{S}\right)}}{c_m^{\left(1\right)} }\right),
\end{equation}
where $c_m^{\left(1\right)} \geq 0$ and $c_m^{\left(2\right)} \leq 0$ are two model parameters to be estimated by the parameter estimation module in Fig. \ref{fig:system}. Figure \ref{fig:qp_rate_model} illustrates the source coding rate vs. QP curves with the HEVC encoder. In total $6$ videos with VGA $\left(640\times 480\right)$ resolution in the ETHZ dataset \cite{ELSG08} and $2$ videos with $720$p $\left(1280\times 720\right)$ resolution recorded in the University of Washington (UW) are tested. And the QP vs. source coding rate model is accurate by adjusting the two parameters with curve fitting. 

\begin{figure}[b]
\centering{\epsfig{file=Fig/QP_Rate_Model.eps,width=3.6in}}
\caption{Curve-fitting result of the model in Eq. \eqref{eq:qp_rate_model} with different videos of VGA and 720p resolutions.}\label{fig:qp_rate_model}
\end{figure}

The first constraint in Eq. \eqref{eq:original_probelm} means that the sum of the block size of each mobile node is limited by the total number of packets allowed to be transmitted in one GoP time period. The second constraint indicates that the source packet of each mobile node should be larger than a pre-defined minimum requirement. The optimization problem in Eq. \eqref{eq:original_probelm} is NP hard since $\mathbf{k}$ and $\mathbf{n}$ are positive integers. By relaxing the last constraint in Eq. \eqref{eq:original_probelm} and taking logarithm of the objective function, the original problem in Eq. \eqref{eq:original_probelm} can be reformulated as:
\begin{equation}
\begin{array}{l}
\!\!\max_{\mathbf{k,n}}\!\!\sum_{m=1}^{M} \!\!N_m\!\!\left(\!\! \log\!\left(\!\!P\left(\!\!q_m\left(\frac{k_m S}{T^{\left(\text{GoP}\right)}}\!\!\right)\!\!\right)\!\!\right)\!\!+\!\!\log\left(f_m\left(k_m,\!n_m\!\right)\!\right)\!\!\right)\\
\begin{array}{ll}
\text{subject to}&\sum_{m=1}^{M}n_m\leq\frac{R^{\left(\text{T}\right)}T^{\left(\text{GoP}\right)}}{S},\\
& k_m \geq \frac{R^{\left(\min\right)}T^{\left(\text{GoP}\right)}}{S}, \forall m,\\
& n_m \geq k_m, \forall m.
\end{array}
\end{array}
\end{equation}
By applying the APP-FEC BCR approximation in Eq. \eqref{eq: BCR_appx_final} and substituting the optimization variables $\tilde{n}_m=\sqrt{n_m}$ and $\tilde{k}_m=\sqrt{k_m}$ for all $m$, The optimization problem becomes:
\begin{equation}\label{eq:finalProblem}
\begin{array}{l}
\max_{\mathbf{\tilde{k},\tilde{n}}}\sum_{m=1}^{M}N_m\cdot \log\left(P\left(q_m\left(\frac{\tilde{k}^2_m\cdot S}{T^{\left(\text{GoP}\right)}}\right)\right)\right)\\
+\sum_{m=1}^{M}N_m\log\left(\Phi\left(\frac{\tilde{n}_m\left(1-p_m\right)-\frac{\tilde{k}_m^2}{\tilde{n}_m}}{\sqrt{p_m\left(1-p_m\right)}}\right)\right)\\
\begin{array}{ll}
\text{subject to}&\sum_{m=1}^{M}\tilde{n}_m^2\leq\frac{R^{\left(\text{T}\right)}T^{\left(\text{GoP}\right)}}{S},\\
& \tilde{k}_m \geq \sqrt{\frac{R^{\left(\min\right)}T^{\left(\text{GoP}\right)}}{S}}, \forall m,\\
& \tilde{n}_m \geq \tilde{k}_m, \forall m,
\end{array}
\end{array}
\end{equation}
which can be shown as a convex optimization problem \cite{BoVa04} (see Appendix A) and can be solved by convex optimization tools such as CVX \cite{CVX}. In the objective function of Eq. \eqref{eq:finalProblem}, the first line is for source coding rate allocation and the second line is for APP-FEC rate allocation. The rate allocation of each mobile node is also proportional to the number of detected people $N_m$, which replects the pedestrian density in the camera view of each mobile node. Note that the optimized solutions $\mathbf{k}^*$ and $\mathbf{n}^*$ do not need to be converted to integers since the source coding rate $r_m^{\left(\text{S}\right)}=k_m^*\cdot S/T^{\text{GoP}}$ and the transmission data rate $r_m^{\left(\text{B}\right)}=n_m^*\cdot S/T^{\text{GoP}}$ of the mobile node $m$ are the corresponding encoding targets for the next round, which may slightly different to the actural encoding rates due to the rate-control mechanism of the encoder.

\section{Simulation Results}
In this section, the proposed QoC-driven rate allocation scheme is evaluated by plenty of simulations. In total four video clips are used to compete for the limited wireless resources: two videos ``LINTHESCHER" and ``LOEWENPLATZ" from the ETHZ data set \cite{ELSG08} and two videos recorded in the UW campus. Table \ref{Table: video} summarizes the resolutions and human densities of the four videos. HEVC (X265 implementation) \cite{X265} is used as the video encoder. The frame rate and GoP are set as $25$ fps and $16$ respectively for all the videos. The encoding pattern in each GoP block is one I-frame followed by $15$ P-frames. $25$ GoPs ($400$ frames) are simulated for each video. Figure \ref{fig:sampleFrames} shows the sample video frames of the four videos. 


\begin{table}[t]
\renewcommand{\arraystretch}{1.3}
\caption{Video Resolutions and Human Densities}
%\vspace{-.2in}
\begin{center}
\begin{tabular}{|c!{\vrule width 2pt}c|c|}
\hline
\textbf{Video} & \textbf{Resolution} & \textbf{Human Density} \\ \noalign{\hrule height 2pt}
\textbf{UW 1} &$1280\times720$ &Low \\ \hline
\textbf{UW 2} &$1280\times720$ &Medium \\ \hline 
\textbf{LINTHESCHER} &$640\times480$ &High \\ \hline
\textbf{LOEWENPLATZ} &$640\times480$ &High \\
\hline
\end{tabular}
\end{center}
\label{Table: video}
%\vspace{-.1in}
\end{table}

\begin{figure}[t]
\centering{\includegraphics[width=3.5 in]{Fig/sampleFrame.pdf}}
\caption{The sample frames of the three videos. Top left: ``UW 1"; Top right: ``LINTHESCHER"; Bottom left: ``UW 2"; Bottom right: ``LOEWENPLATZ".}
\label{fig:sampleFrames}
\end{figure}

Table \ref{Table: schemes} summarizes the proposed and other rate allocation schemes in the control group. We compare the proposed scheme with other three schemes. The first one is driven by video distortion measured by the mean-squared-error (MSE). We adopte a rate-distortion model in \cite{HOSC10} as:
\begin{equation}
d_m\left(r\right)=c_m^{\left(3\right)}r^{c_m^{\left(4\right)}},
\end{equation}
where $d_m\left(r\right)$ is the distortion in terms of MSE for the mobile node $m$. $c_m^{\left(3\right)}$ and $c_m^{\left(4\right)}$ are two parameters to be determined by curve-fitting. The MSE-driven rate allocation problem is expressed as:
\begin{equation}
\begin{array}{rl}
\min_{\mathbf{\tilde{k}},\mathbf{\tilde{n}}} &\sum_{m=1}^{M}d_m\left(\frac{\tilde{k}^2_m \cdot S}{T^{\left(\text{GoP}\right)}}\right) \\
\text{subject to} & \sum\limits_{m=1}^{M}\tilde{n}^2_m\leq \frac{R^{\left(\text{T}\right)}T^{\left(\text{GoP}\right)}}{S}\\
& \tilde{k}_m \geq \sqrt{\frac{R^{\left(\min\right)}T^{\left(\text{GoP}\right)}}{S}}, \forall m, \\
& \tilde{n}_m \geq \tilde{k}_m, \forall m \\
& \log\Phi\left(\frac{\tilde{n}_m\left(1-p_m\right)-\frac{\tilde{k}_m^2}{\tilde{n}_m}}{\sqrt{p_m\left(1-p_m\right)}}\right) \geq \log(P^{\left(\text{req}\right)}), \forall m,
\end{array}
\end{equation}
where $P^{\left(\text{req}\right)}$ is a pre-defined BCR requirement, which is set as $0.99$ \cite{WSHZ13} in this paper. The minimum data rate requirement $R^{\left(\min\right)}$ in our proposed scheme and the MSE-driven rate allocation scheme are both set as $200$ Kbps.

\begin{table}[t]
\renewcommand{\arraystretch}{1.3}
\caption{Video Resolutions and Human Densities}
%\vspace{-.2in}
\begin{center}
\begin{tabular}{|p{1.9cm}!{\vrule width 2pt}p{2.7cm}|p{2.7cm}|}
\hline
\textbf{Rate Allocation Scheme} & \textbf{Source Coding Rate} & \textbf{APP-FEC Rate} \\ \noalign{\hrule height 2pt}
\textbf{Proposed} & Adaptive, QoC-driven & Adaptive, QoC-driven \\ \hline
\textbf{MSE} & Adaptive, MSE-driven & Adaptive, determined by pre-determined targets \\ \hline 
\textbf{Equal ($0.5$)} & Fixed, $50$\% of total available throughput  & Fixed, $50$\% of total available throughput \\ \hline
\textbf{Equal ($0.8$)} &Fixed, $80$\% of total available throughput &Fixed, $20$\% of total available throughput \\
\hline
\end{tabular}
\end{center}
\label{Table: schemes}
%\vspace{-.1in}
\end{table}



\section{Conclusions and Future Work}
In this paper, a QoC-driven joint source coding and APP-FEC rates allocation scheme for video analysis purposes in mobile surveillance network with multiple moving cameras is proposed. Different with the previous wireless video transmission studies, which focus on improving traditional QoS or QoE measures to meet the wireless network conditions or the users' perception satisfactions, the proposed scheme tries to optimize the wireless resource usage so that more accurate human detections can be performed at the cloud server based on the received videos. This study is conducted with HEVC video codecs and the DPM object detector. We have evaluated the human detection model with different QPs of the HEVC encoder. The APP-FEC is used for more reliable wireless data deliveries. Also, our proposed joint source encoding and APP-FEC rate allocation problem can be formulated as a convex optimization problem, which can be efficiently solved by standard solvers. Plenty of simulations with different pedestrain densities and wireless conditions show the effectiveness our proposed scheme and its favorable performance comparing with the equal rate allocation and MSE-driven rate allocation schemes.

The proposed scheme only considers human detection as the video analytic purpose, which is the first step for more sophisticated systems such as human tracking, behavior understanding etc. Therefore, plenty of furture studies can be conducted in computer vision, video compression and video transmission areas. In computer vision area, more robust video analytic and computer graphics technologies, including object detection/tracking, pose and event recognitions, 3-D scene reconstructions etc., are required when video compression and transmission errors exist. In video compression area, traditional designs are for improving the rate-distortion properties so that more bit rate can be saved while keeping as much as the original video qualities. However, more efficient video compression schemes could be developed if video qualities can be much reduced while some specific useful features for video anayltic purposes are well kept. In wireless video transmission area, many transmission protocals and strategies can be re-evaluated if the video sequences are transmitted for video analytics rather than human perceptions.
\appendices
\section{Convexity of the Objective Problem in Eq. \eqref{eq:finalProblem}}
For the first half of the objective function in Eq. \eqref{eq:finalProblem}, $q_m\left(.\right)$ is convex and non-increasing if $c_m^{\left(2\right)}\leq 0$. Therefore, $q_m\left(\tilde{k}_m^2\cdot S/T^{\left(\text{GoP}\right)}\right)$ is convex by the composition rule \cite{BoVa04}. Since $P\left(\cdot \right)$ is concave and decreasing, $P\left(q_m\left(\tilde{k}_m^2\cdot S/T^{\left(\text{GoP}\right)}\right)\right)$ is concave by the composition rule. Also, $\log\left(\cdot\right)$ is concave and increasing, $\log\left(P\left(q_m\left(\tilde{k}_m^2\cdot S/T^{\left(\text{GoP}\right)}\right)\right)\right)$ is therefore concave. For the second half of the objective function in Eq. \eqref{eq:finalProblem}, $g\left(\tilde{k}_m,\tilde{n}_m\right)=\tilde{k}^2_m/\tilde{n}_m$ is a quadratic-over-linear function, which is convex if $\tilde{n}_m>0$ \cite{BoVa04}. 
\begin{equation}
h\left(\tilde{k}_m,\tilde{n}_m\right) = \frac{\tilde{n}_m\left(1-p_m\right)-\frac{\tilde{k}_m^2}{\tilde{n}_m}}{\sqrt{p_m\left(1-p_m\right)}}
\end{equation}
is concave. Furthermore, $\Phi\left(\cdot\right)$ is log-concave \cite{BoVa04} and non-decreasing. $\log\left(\Phi\left(h\left(\tilde{k}_m,\tilde{n}_m\right)\right)\right)$ is concave. Since $N_m$ is non-negative, the objective function in Eq. \eqref{eq:finalProblem} is non-negative sums of concave functions, which is also concave \cite{BoVa04}. Therefore, the optimization problem in Eq. \eqref{eq:finalProblem} is a convex optimization problem since the objective function is concave and the feasible set determined by all the constraints is convex.


\bibliographystyle{IEEEtran}
\bibliographystyle{unsrt}\bibliography{IEEEabrv,QoC,tcsvt, ICC15_2}




% that's all folks
\end{document}


